

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nems.models &mdash; nems 0.1 documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="top" title="nems 0.1 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="../../index.html" class="fa fa-home"> nems</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../install.html#basic">Basic</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../quickstart.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../quickstart.html#bugs">Bugs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api.html#module-nems.models">nems.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api.html#module-nems.objectives">nems.objectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api.html#module-nems.tentbasis">nems.tentbasis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api.html#module-nems.sensitivity">nems.sensitivity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api.html#module-nems.simulate">nems.simulate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api.html#module-nems.datastore">nems.datastore</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../changelog.html#v0-1-work-in-progress">v0.1 (Work in Progress)</a></li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">nems</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../index.html">Module code</a> &raquo;</li>
      
    <li>nems.models</li>
      <li class="wy-breadcrumbs-aside">
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <h1>Source code for nems.models</h1><div class="highlight"><pre>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Objects for fitting and testing Neural Encoding models</span>

<span class="sd">This module provides a set of objects useful for fitting neural encoding models. These are typically probabilistic</span>
<span class="sd">models of the response of a sensory neuron to an external stimulus. For example, linear-nonlinear-poisson (LNP) or</span>
<span class="sd">generalized linear models (GLMs) fall under this category.</span>

<span class="sd">The module exposes classes which contain methods useful for training and testing encoding models given neural data</span>
<span class="sd">recorded in an experiment. For more information, see the documentation (TODO: website)</span>

<span class="sd">Classes</span>
<span class="sd">-------</span>
<span class="sd">- `NeuralEncodingModel` -- A super class which contains methods that are common to all encoding models</span>
<span class="sd">- `LNLN` -- A subclass of `NeuralEncodingModel` that fits two layer models consisting of alternating layers of linear filtering and nonlinear thresholding operations. The parameters for the filter and nonlinearities of the first layer are learned, while the linear filter and nonlinearity of the second layer are fixed.</span>

<span class="sd">References</span>
<span class="sd">----------</span>
<span class="sd">Coming soon</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="c"># imports</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">tentbasis</span>
<span class="kn">from</span> <span class="nn">.sfo_admm</span> <span class="kn">import</span> <span class="n">SFO</span>
<span class="kn">from</span> <span class="nn">proxalgs.core</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span> <span class="nn">proxalgs</span> <span class="kn">import</span> <span class="n">operators</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="c"># exports</span>
<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;NeuralEncodingModel&#39;</span><span class="p">,</span> <span class="s">&#39;LNLN&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="NeuralEncodingModel"><a class="viewcode-back" href="../../api.html#nems.models.NeuralEncodingModel">[docs]</a><span class="k">class</span> <span class="nc">NeuralEncodingModel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Neural enoding model object</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modeltype</span><span class="p">,</span> <span class="n">stimulus</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">filter_dims</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="n">frac_train</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">spikes</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

        <span class="c"># model name / subclass</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modeltype</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">modeltype</span><span class="p">)</span>

        <span class="c"># model properties</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">rate</span><span class="o">.</span><span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">filter_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filter_dims</span> <span class="o">=</span> <span class="n">filter_dims</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stim_dim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">filter_dims</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="c"># the length of the filter must be smaller than the length of the experiment</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="s">&#39;The temporal filter length must be less than the experiment length.&#39;</span>

        <span class="c"># filter dimensions must be (n1 x n2 x tau), while the stimulus dimensions should be (n1*n2 x t)</span>
        <span class="k">assert</span> <span class="n">stimulus</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">stim_dim</span><span class="p">,</span> <span class="s">&#39;Stimulus size does not match up with filter dimensions&#39;</span>

        <span class="c"># split data into minibatches</span>
        <span class="k">if</span> <span class="n">minibatch_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>

            <span class="c"># choose number of minibatches as sqrt(T)/10</span>
            <span class="c"># minibatch_size = np.ceil(0.1 * np.sqrt(self.num_samples)).astype(&#39;int&#39;)</span>
            <span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">&#39;int&#39;</span><span class="p">)</span>
            <span class="n">num_minibatches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">/</span> <span class="n">minibatch_size</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_minibatches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">/</span> <span class="n">minibatch_size</span><span class="p">)</span>

        <span class="c"># slice the z-scored stimulus every tau samples, for easier dot products</span>
        <span class="n">slices</span> <span class="o">=</span> <span class="n">_rolling_window</span><span class="p">((</span><span class="n">stimulus</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stimulus</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">stimulus</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span>

        <span class="c"># store stimulus and rate data for each minibatch in a list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_minibatches</span><span class="p">):</span>

            <span class="c"># indices for this minibatch</span>
            <span class="n">minibatch_indices</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">idx</span> <span class="o">*</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">minibatch_size</span><span class="p">)</span>

            <span class="c"># z-score the stimulus and save each minibatch, along with the rate and spikes if given</span>
            <span class="k">if</span> <span class="n">spikes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s">&#39;stim&#39;</span><span class="p">:</span> <span class="n">slices</span><span class="p">[:,</span> <span class="n">minibatch_indices</span><span class="p">,</span> <span class="p">:],</span>
                    <span class="s">&#39;rate&#39;</span><span class="p">:</span> <span class="n">rate</span><span class="p">[</span><span class="n">minibatch_indices</span><span class="p">],</span>
                    <span class="s">&#39;spikes&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">spikes</span><span class="p">[</span><span class="n">minibatch_indices</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">})</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s">&#39;stim&#39;</span><span class="p">:</span> <span class="n">slices</span><span class="p">[:,</span> <span class="n">minibatch_indices</span><span class="p">,</span> <span class="p">:],</span>
                    <span class="s">&#39;rate&#39;</span><span class="p">:</span> <span class="n">rate</span><span class="p">[</span><span class="n">minibatch_indices</span><span class="p">]</span>
                <span class="p">})</span>

        <span class="c"># set and store random seed (for reproducibility)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

        <span class="c"># split up data into train/validation/test sets</span>
        <span class="n">num_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">frac_train</span> <span class="o">*</span> <span class="n">num_minibatches</span><span class="p">))</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_minibatches</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">num_train</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">num_train</span><span class="p">:]</span>

        <span class="c"># compute the STA</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_getsta</span><span class="p">()</span>

        <span class="c"># compute the mean firing rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanrate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">&quot;Neural encoding model, &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">modeltype</span>

    <span class="k">def</span> <span class="nf">_getsta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute an STA</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">&#39;rate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
        <span class="n">stas</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">&#39;stim&#39;</span><span class="p">],</span> <span class="n">d</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">/</span> <span class="n">num_samples</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stas</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_dims</span><span class="p">)</span>

<div class="viewcode-block" id="NeuralEncodingModel.add_regularizer"><a class="viewcode-back" href="../../api.html#nems.models.NeuralEncodingModel.add_regularizer">[docs]</a>    <span class="k">def</span> <span class="nf">add_regularizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta_key</span><span class="p">,</span> <span class="n">proxfun</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a proximal operator / objective to the objective, using the proxalgs package</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta_key : string</span>
<span class="sd">            The key corresponding to the parameters that this proximal function should be applied to</span>

<span class="sd">        proxfun : string</span>
<span class="sd">            The name of the corresponding function in the proxalgs.operators module</span>

<span class="sd">        \\*\\*kwargs : keyword arguments</span>
<span class="sd">            Any keyword arguments required by proxfun</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># ensure regularizers have been initialized</span>
        <span class="k">assert</span> <span class="s">&quot;regularizers&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="p">,</span> <span class="s">&quot;Regularizers dictionary has not been initialized!&quot;</span>
        <span class="k">assert</span> <span class="n">theta_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizers</span><span class="p">,</span> <span class="s">&quot;Key &#39;&quot;</span> <span class="o">+</span> <span class="n">theta_key</span> <span class="o">+</span> <span class="s">&quot;&#39; not found in self.regularizers!&quot;</span>

        <span class="c"># build a wrapper function that applies the desired proximal operator to each element of the parameter array</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">rho</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

            <span class="c"># creating a copy of the parameters isolates them from any modifications applied by proxfun</span>
            <span class="n">theta_new</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

            <span class="c"># apply the proximal operator to each element in the parameter array</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
                <span class="n">theta_new</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">operators</span><span class="p">,</span> <span class="n">proxfun</span><span class="p">)(</span><span class="n">param</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="n">rho</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">theta_new</span>

        <span class="c"># add this proximal operator function to the list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizers</span><span class="p">[</span><span class="n">theta_key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
</div>
<div class="viewcode-block" id="NeuralEncodingModel.test"><a class="viewcode-back" href="../../api.html#nems.models.NeuralEncodingModel.test">[docs]</a>    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the model on held out data</span>

<span class="sd">        Relies on the model subclass having a `metrics` method, which accepts an index into the data array and returns</span>
<span class="sd">        a dictionary containing various metrics evaluated given the current value of the parameters (`theta`) on the</span>
<span class="sd">        minibatch of data at the given index</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        results : DataFrame</span>
<span class="sd">            A pandas dataframe with the following columsn: the minibatch index, a &#39;train&#39; or &#39;test&#39; label, and any</span>
<span class="sd">            keywords returned by the metrics function. Each row in the dataframe consists of the metrics evaluated</span>
<span class="sd">            on a single minibatch of data.</span>

<span class="sd">        stats : dict</span>
<span class="sd">            Statistics on just the held out minibatches. Keys correspond to the keys in metrics, values are the average</span>
<span class="sd">            computed over the test minibatches.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Given an initialized and trained instance of NeuralEncodingModel, you can test the model on</span>
<span class="sd">        held out data as follows:</span>

<span class="sd">        &gt;&gt;&gt; results, avg = model.test()</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">class_key</span> <span class="o">=</span> <span class="s">&#39;set&#39;</span>

        <span class="c"># helper function</span>
        <span class="k">def</span> <span class="nf">update_results</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">class_label</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">class_key</span><span class="p">:</span> <span class="n">class_label</span><span class="p">})</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
            <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

        <span class="c"># evaluate metrics on train / test data</span>
        <span class="p">[</span><span class="n">update_results</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s">&#39;train&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_indices</span><span class="p">]</span>
        <span class="p">[</span><span class="n">update_results</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s">&#39;test&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_indices</span><span class="p">]</span>

        <span class="c"># create DataFrame to store results</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">results</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">indices</span><span class="p">)</span>

        <span class="c"># compute the average over the test minibatches</span>
        <span class="n">avg</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">class_key</span><span class="p">]</span> <span class="o">==</span> <span class="s">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">avg</span>

</div></div>
<div class="viewcode-block" id="LNLN"><a class="viewcode-back" href="../../api.html#nems.models.LNLN">[docs]</a><span class="k">class</span> <span class="nc">LNLN</span><span class="p">(</span><span class="n">NeuralEncodingModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stim</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">filter_dims</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">frac_train</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">num_subunits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">num_tents</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">sigmasq</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">tent_type</span><span class="o">=</span><span class="s">&#39;gaussian&#39;</span><span class="p">,</span> <span class="n">spikes</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a two layer cascade (LNLN) model</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; model = LNLN(stim, rate, filter_dims)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        stim : array_like</span>
<span class="sd">            a spatiotemporal stimulus. must have dimensions of (N by T), where N is the dimensionality of the</span>
<span class="sd">            first linear filter, and T is the number of samples / time points in the experiment</span>

<span class="sd">        rate : array_like</span>
<span class="sd">            the recorded firing rate corresponding to the stimulus, must have dimensions of (T,)</span>

<span class="sd">        filter_dims : tuple</span>
<span class="sd">            a tuple defining the dimensions for the spatiotemporal filter. e.g., (n,n,tau) for a 2D stimulus or</span>
<span class="sd">            or (n,tau) for a bars stimulus. tau must be less than T, the length of the experiment, and N (the</span>
<span class="sd">            stimulus dimensionality) must equal the product of all but the last item in the tuple.</span>

<span class="sd">        minibatch_size : int, optional</span>
<span class="sd">            the size of each minibatch, in samples. defaults to a value such that the number of minibatches is</span>
<span class="sd">            roughly equal to :math:`0.1 * sqrt(T)`</span>

<span class="sd">        frac_train : float, optional</span>
<span class="sd">            number between 0 and 1, gives the fraction of minibatches used for training (default: 0.8)</span>

<span class="sd">        num_subunits : int, optional</span>
<span class="sd">            number of subunits to use (default: 1), if a initial W is given, this parameter is unused</span>

<span class="sd">        num_tents : int, optional</span>
<span class="sd">            number of tent basis functions to use for parameterizing nonlinearities</span>

<span class="sd">        sigmasq : float, optional</span>
<span class="sd">            the size / scale of each tent basis function (default: 0.2)</span>

<span class="sd">        tent_type : string</span>
<span class="sd">            the type of tent basis function to use (default: &#39;Gaussian&#39;)</span>

<span class="sd">        Other Parameters</span>
<span class="sd">        ----------------</span>
<span class="sd">        \\*\\*kwargs : keyword arguments</span>
<span class="sd">            if given arguments with the keys `W` or `f`, then those values are used to initialize the filter</span>
<span class="sd">            or nonlinearity parameters, respectively.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># initialize the model object</span>
        <span class="n">NeuralEncodingModel</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">&#39;lnln_exp&#39;</span><span class="p">,</span> <span class="n">stim</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">filter_dims</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span>
                                     <span class="n">frac_train</span><span class="o">=</span><span class="n">frac_train</span><span class="p">,</span> <span class="n">spikes</span><span class="o">=</span><span class="n">spikes</span><span class="p">)</span>

        <span class="c"># default # of subunits</span>
        <span class="k">if</span> <span class="s">&#39;W&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_subunits</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_subunits</span> <span class="o">=</span> <span class="n">num_subunits</span>

        <span class="c"># initialize tent basis functions</span>
        <span class="n">num_tent_samples</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="n">tent_span</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>          <span class="c"># suitable for z-scored input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tentparams</span> <span class="o">=</span> <span class="n">tentbasis</span><span class="o">.</span><span class="n">build_tents</span><span class="p">(</span><span class="n">num_tent_samples</span><span class="p">,</span> <span class="n">tent_span</span><span class="p">,</span> <span class="n">num_tents</span><span class="p">,</span>
                                                <span class="n">tent_type</span><span class="o">=</span><span class="n">tent_type</span><span class="p">,</span> <span class="n">sigmasq</span><span class="o">=</span><span class="n">sigmasq</span><span class="p">)</span>

        <span class="c"># initialize parameter dictionary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_subunits</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stim_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_subunits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tentparams</span><span class="p">[</span><span class="s">&#39;num_tents&#39;</span><span class="p">]))</span>

        <span class="c"># initialize filter parameters</span>
        <span class="k">if</span> <span class="s">&#39;W&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>

            <span class="c"># ensure dimensions are consistent</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s">&quot;Shape of the filters (`W` keyword argument) &quot;</span> \
                                                                    <span class="s">&quot;are inconsistent with the given filter dimensions.&quot;</span>

            <span class="c"># normalize each of the given filters</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">]):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">_nrm</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="c"># multiple subunits: random initialization</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_subunits</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_subunits</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">_nrm</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stim_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">))</span>

            <span class="c"># single subunit: initialize with the STA</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">_nrm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sta</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">sta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="c"># initialize nonlinearity parameters</span>
        <span class="k">if</span> <span class="s">&#39;f&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>

            <span class="c"># ensure dimensions are consistent</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s">&quot;Shape of the nonlinearity parameters&quot;</span> \
                                                                    <span class="s">&quot; (`f` keyword argument) are inconsistent with &quot;</span> \
                                                                    <span class="s">&quot;the number of tent basis functions.&quot;</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="c"># initialize each subunit nonlinearity to be linear</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_subunits</span><span class="p">):</span>
                <span class="n">ts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tentparams</span><span class="p">[</span><span class="s">&#39;tent_span&#39;</span><span class="p">]</span>
                <span class="n">nonlin_init</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ts</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">tentparams</span><span class="p">[</span><span class="s">&#39;num_tent_samples&#39;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tentparams</span><span class="p">[</span><span class="s">&#39;Phi&#39;</span><span class="p">],</span> <span class="n">nonlin_init</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c"># initialize regularizers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularizers</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;W&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(),</span> <span class="s">&#39;f&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">()}</span>

<div class="viewcode-block" id="LNLN.f_df"><a class="viewcode-back" href="../../api.html#nems.models.LNLN.f_df">[docs]</a>    <span class="k">def</span> <span class="nf">f_df</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">param_gradient</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the negative log-likelihood objective and gradient for the LNLN model class</span>

<span class="sd">        f, df = f_df(self, W, f, data)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        W : array_like</span>
<span class="sd">            A numpy array containing parameter values for the first layer linear filters in the LNLN model</span>

<span class="sd">        f : array_like</span>
<span class="sd">            A numpy array containing parameter values for the first layer nonlinearity in the LNLN model</span>

<span class="sd">        data : dict</span>
<span class="sd">            Dictionary containing two keys: `stim` and `rate`, each of which is a numpy array.</span>

<span class="sd">        param_gradient : string (optional, default=None)</span>
<span class="sd">            A string indicating which parameters to compute the gradient for, either `W` or `f`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        obj_value : float</span>
<span class="sd">            The negative log-likelihood objective value. Lower values indicate a better fit to the data.</span>

<span class="sd">        obj_gradient : array_like</span>
<span class="sd">            Contains the gradient (as a numpy array) with respect to the parameters given by `param_gradient`</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># f is (K,P)</span>
        <span class="c"># W is (K,N,tau)</span>
        <span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">tau</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">m</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="n">tau</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c"># estimate firing rate and get model response</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">zgrad</span><span class="p">,</span> <span class="n">logr</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">({</span><span class="s">&#39;W&#39;</span><span class="p">:</span> <span class="n">W</span><span class="p">,</span> <span class="s">&#39;f&#39;</span><span class="p">:</span> <span class="n">f</span><span class="p">},</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;stim&#39;</span><span class="p">])</span>

        <span class="c"># objective in bits (log-likelihood difference between model and mean firing rates)</span>
        <span class="n">obj_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">logr</span><span class="p">)</span>

        <span class="c"># factor in front of the gradient</span>
        <span class="n">grad_factor</span> <span class="o">=</span> <span class="n">r</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">]</span>  <span class="c"># dims: (M)</span>

        <span class="c"># compute gradient</span>
        <span class="k">if</span> <span class="n">param_gradient</span> <span class="o">==</span> <span class="s">&#39;W&#39;</span><span class="p">:</span>
            <span class="n">nonlin_proj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">f</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">zgrad</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c"># dims: (K, M)</span>
            <span class="n">weighted_proj</span> <span class="o">=</span> <span class="n">grad_factor</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">nonlin_proj</span>  <span class="c"># dims: (K, M)</span>
            <span class="n">obj_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">weighted_proj</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;stim&#39;</span><span class="p">],</span> <span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">param_gradient</span> <span class="o">==</span> <span class="s">&#39;f&#39;</span><span class="p">:</span>
            <span class="n">obj_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">grad_factor</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">obj_gradient</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="k">return</span> <span class="n">obj_value</span><span class="p">,</span> <span class="n">obj_gradient</span>
</div>
<div class="viewcode-block" id="LNLN.fit"><a class="viewcode-back" href="../../api.html#nems.models.LNLN.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_alt</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">num_likelihood_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs an optimization algorithm to learn the parameters of the model given training data and regularizers</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        num_alt : int, optional</span>
<span class="sd">            The number of times to alternate between optimizing nonlinearities and optimizing filters. Default: 2</span>

<span class="sd">        max_iter : int, optional</span>
<span class="sd">            The maximum number of steps to take during each leg of the alternating minimization. Default: 25</span>

<span class="sd">        num_likelihood_steps : int, optional</span>
<span class="sd">            The number of steps to take when optimizing the data likelihood term (using SFO)</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        See the `proxalgs` module for more information on the optimization algorithm</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># grab the initial parameters</span>
        <span class="n">theta_current</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;W&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="s">&#39;f&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta_init</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()}</span>

        <span class="c"># get list of training data</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_indices</span><span class="p">]</span>

        <span class="c"># runs the optimization procedure for one set of parameters (a single leg of the alternating minimization)</span>
        <span class="k">def</span> <span class="nf">optimize_param</span><span class="p">(</span><span class="n">f_df_wrapper</span><span class="p">,</span> <span class="n">param_key</span><span class="p">):</span>

            <span class="c"># initialize the optimizer object</span>
            <span class="n">opt</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="p">(</span><span class="s">&#39;sfo&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">SFO</span><span class="p">(</span><span class="n">f_df_wrapper</span><span class="p">,</span> <span class="n">theta_current</span><span class="p">[</span><span class="n">param_key</span><span class="p">],</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                            <span class="n">num_steps</span><span class="o">=</span><span class="n">num_likelihood_steps</span><span class="p">)</span>

            <span class="c"># add regularization terms</span>
            <span class="p">[</span><span class="n">opt</span><span class="o">.</span><span class="n">add_regularizer</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="k">for</span> <span class="n">reg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizers</span><span class="p">[</span><span class="n">param_key</span><span class="p">]]</span>

            <span class="c"># run the optimization procedure</span>
            <span class="k">return</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">theta_current</span><span class="p">[</span><span class="n">param_key</span><span class="p">],</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="c"># alternating optimization: switch between optimizing nonlinearities, and optimizing filters</span>
        <span class="k">for</span> <span class="n">alt_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_alt</span><span class="p">):</span>

            <span class="c"># Fit nonlinearity</span>
            <span class="c"># wrapper for the objective and gradient</span>
            <span class="k">def</span> <span class="nf">f_df_wrapper</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_df</span><span class="p">(</span><span class="n">theta_current</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">],</span> <span class="n">f</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">param_gradient</span><span class="o">=</span><span class="s">&#39;f&#39;</span><span class="p">)</span>

            <span class="c"># run the optimization procedure for this parameter</span>
            <span class="n">theta_current</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimize_param</span><span class="p">(</span><span class="n">f_df_wrapper</span><span class="p">,</span> <span class="s">&#39;f&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

            <span class="c"># Fit filters</span>
            <span class="c"># wrapper for the objective and gradient</span>
            <span class="k">def</span> <span class="nf">f_df_wrapper</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_df</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">theta_current</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">],</span> <span class="n">d</span><span class="p">,</span> <span class="n">param_gradient</span><span class="o">=</span><span class="s">&#39;W&#39;</span><span class="p">)</span>

            <span class="c"># run the optimization procedure for this parameter</span>
            <span class="n">Wk</span> <span class="o">=</span> <span class="n">optimize_param</span><span class="p">(</span><span class="n">f_df_wrapper</span><span class="p">,</span> <span class="s">&#39;W&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

            <span class="c"># normalize filters</span>
            <span class="k">for</span> <span class="n">fi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Wk</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">Wk</span><span class="p">[</span><span class="n">fi</span><span class="p">]</span> <span class="o">=</span> <span class="n">_nrm</span><span class="p">(</span><span class="n">Wk</span><span class="p">[</span><span class="n">fi</span><span class="p">])</span>

        <span class="c"># store learned parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">theta_current</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="LNLN.metrics"><a class="viewcode-back" href="../../api.html#nems.models.LNLN.metrics">[docs]</a>    <span class="k">def</span> <span class="nf">metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate metrics on a given minibatch.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data_index : int</span>
<span class="sd">            An index into the array of minibatches (`self.data`) the evaluate</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        metrics : dict</span>
<span class="sd">            A dictionary whose keys are the names of metrics applied to evaluate the model parameters on the given</span>
<span class="sd">            minibatch, and whose values are single numbers.</span>

<span class="sd">        See Also</span>
<span class="sd">        --------</span>
<span class="sd">        NeuralEncodingModel.test</span>
<span class="sd">            The `test` function in the super class NeuralEncodingModel relies on the metrics function to return</span>
<span class="sd">            aggregate statistics over all minibatches.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># get this minibatch of data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">data_index</span><span class="p">]</span>

        <span class="c"># compute the model firing rate</span>
        <span class="n">logr</span><span class="p">,</span> <span class="n">rhat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;stim&#39;</span><span class="p">])[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>

        <span class="c"># correlation coefficient</span>
        <span class="n">cc</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">rhat</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">])))[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="c"># log-likelihood improvement over a mean rate model (in bits per spike)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanrate</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">meanrate</span><span class="p">))</span>
        <span class="n">fobj</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">logr</span> <span class="o">-</span> <span class="n">rhat</span><span class="p">))</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">meanrate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

        <span class="c"># mean squared error</span>
        <span class="n">mse</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">rhat</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;rate&#39;</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">{</span><span class="s">&#39;corrcoef&#39;</span><span class="p">:</span> <span class="n">cc</span><span class="p">,</span> <span class="s">&#39;log-likelihood improvement&#39;</span><span class="p">:</span> <span class="n">fobj</span><span class="p">,</span> <span class="s">&#39;mean squared error&#39;</span><span class="p">:</span> <span class="n">mse</span><span class="p">}</span>
</div>
    <span class="k">def</span> <span class="nf">_stim_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the model response and gradient with respect to the stimulus</span>

<span class="sd">        .. warning:: Work in progress</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">u</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">zgrad</span><span class="p">,</span> <span class="n">logr</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">stim</span><span class="p">)</span>

        <span class="n">xgrad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">stim</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>

            <span class="n">xgrad</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">zgrad</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">,</span> <span class="p">:])</span>

        <span class="c"># fgrad = np.tensordot(zgrad, self.theta[&#39;f&#39;], ([0,2],[0,1]))</span>
        <span class="c"># wgrad = np.tensordot(u, self.theta[&#39;W&#39;],([0],[0]))</span>

        <span class="k">return</span> <span class="n">r</span><span class="p">,</span> <span class="n">xgrad</span> <span class="o">*</span> <span class="n">r</span>

    <span class="k">def</span> <span class="nf">_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">stim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the model response given parameters</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : dict</span>
<span class="sd">        stim : array_like</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        u : array_like</span>
<span class="sd">        z : array_like</span>
<span class="sd">        zgrad : array_like</span>
<span class="sd">        logr : array_like</span>
<span class="sd">        r : array_like</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># filter projection</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="s">&#39;W&#39;</span><span class="p">],</span> <span class="n">stim</span><span class="p">,</span> <span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>  <span class="c"># dims: (K x M)</span>

        <span class="c"># evaluate input at tent basis functions</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">zgrad</span> <span class="o">=</span> <span class="n">tentbasis</span><span class="o">.</span><span class="n">eval_tents</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tentparams</span><span class="p">)</span>

        <span class="c"># compute log(rate) and the firing rate</span>
        <span class="n">logr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="s">&#39;f&#39;</span><span class="p">],</span> <span class="n">z</span><span class="p">,</span> <span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>  <span class="c"># dims: (M)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logr</span><span class="p">)</span>  <span class="c"># dims: (M)</span>

        <span class="k">return</span> <span class="n">u</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">zgrad</span><span class="p">,</span> <span class="n">logr</span><span class="p">,</span> <span class="n">r</span>

</div>
<span class="k">def</span> <span class="nf">_rolling_window</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">window</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make an ndarray with a rolling window of the last dimension</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : array_like</span>
<span class="sd">        Array to add rolling window to</span>
<span class="sd">    window : int</span>
<span class="sd">        Size of rolling window</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Array that is a view of the original array with a added dimension</span>
<span class="sd">    of size w.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; x=np.arange(10).reshape((2,5))</span>
<span class="sd">    &gt;&gt;&gt; rolling_window(x, 3)</span>
<span class="sd">    array([[[0, 1, 2], [1, 2, 3], [2, 3, 4]],</span>
<span class="sd">           [[5, 6, 7], [6, 7, 8], [7, 8, 9]]])</span>

<span class="sd">    Calculate rolling mean of last dimension:</span>

<span class="sd">    &gt;&gt;&gt; np.mean(rolling_window(x, 3), -1)</span>
<span class="sd">    array([[ 1.,  2.,  3.],</span>
<span class="sd">           [ 6.,  7.,  8.]])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">window</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s">&quot;`window` must be at least 1.&quot;</span>
    <span class="k">assert</span> <span class="n">window</span> <span class="o">&lt;</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s">&quot;`window` is too long.&quot;</span>

    <span class="c"># # with strides</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">window</span><span class="p">,</span> <span class="n">window</span><span class="p">)</span>
    <span class="n">strides</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">strides</span> <span class="o">+</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">as_strided</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_nrm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalizes data in the given array x by the (vectorized) 2-norm</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : array_like</span>
<span class="sd">        The input to be normalized</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    xn : array_like</span>
<span class="sd">        A version of the input array that has been scaled so it has a unit vectorized 2-norm</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</pre></div>

          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Niru Maheswaranathan.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>